{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Marcket Prediction using Daily News Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to predict whether the stockmarket value will rise or fall based on the daily news from top 25 news outlets. The data used  for this project is obtained from Kaggle datasets which can be found at https://www.kaggle.com/aaron7sun/stocknews\n",
    "\n",
    "The file stockMarketAndNewsData.csv contains all the required data. The columns in the data include date, label (wheher the stock value inclreased or droped), and Top1-Top25 for the text of the daily top 25 news headlines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from pyspark.sql.functions import udf, concat, col, lit\n",
    "from pyspark.sql.types import IntegerType, ArrayType, StringType, DoubleType\n",
    "import string\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, CountVectorizer, Tokenizer, StopWordsRemover, NGram\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and transform data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove puntuation marks from the news\n",
    "\n",
    "removePunctuation = udf(lambda x: ''.join([' ' if ch in string.punctuation else ch for ch in x]))\n",
    "data = data.withColumn('allNews', removePunctuation(data.allNews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#replace null values with empty string\n",
    "data = data.na.fill(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only the columns that represent the news\n",
    "newsColumns = [x for x in data.columns if x not in ['Date', 'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge news from different sources per day\n",
    "\n",
    "data = data.withColumn(\"allNews\", data.Top1)\n",
    "for i in range(2, len(newsColumns)+1):\n",
    "    colName = 'Top' + str(i)\n",
    "    data = data.withColumn('allNews', concat(col(\"allNews\"), lit(\" \"), col(colName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove puntuation marks from the news\n",
    "\n",
    "removePunctuation = udf(lambda x: ''.join([' ' if ch in string.punctuation else ch for ch in x]))\n",
    "data = data.withColumn('allNews', removePunctuation(data.allNews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split the news into words\n",
    "\n",
    "splitNews = udf(lambda s: [x for x in s.split(' ') if (x != u'' and len(x) >= 2)], ArrayType(StringType(), True))\n",
    "data = data.withColumn('words', splitNews(data.allNews)).select('Date', 'label', 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove the stop words\n",
    "\n",
    "myStopwordRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"stopRemoved\")\n",
    "data = myStopwordRemover.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create ngrams of size 2\n",
    "\n",
    "myngram = NGram(inputCol=\"stopRemoved\", outputCol=\"ngrams\", n=2)\n",
    "data = myngram.transform(data)\n",
    "data = data.withColumn('ngrams', data.ngrams.cast(ArrayType(StringType(), True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply count vectorizer to convert to vector of counts of the ngrams\n",
    "\n",
    "myCountVectorizer = CountVectorizer(inputCol=\"ngrams\", outputCol=\"countVect\", minDF=1.0)\n",
    "data = myCountVectorizer.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the prediction model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the label using StringINdexer\n",
    "\n",
    "si_label = StringIndexer(inputCol=\"label\", outputCol=\"label2\", handleInvalid=\"skip\")\n",
    "data = si_label.fit(data).transform(data)\n",
    "data.drop('label')\n",
    "data = data.withColumn('label', data.label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide into training and test data\n",
    "\n",
    "trainData = data[data['Date'] < '20150101']\n",
    "testData = data[data['Date'] >= '20141231']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the random forest classifier model\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"countVect\", numTrees=3, maxDepth=4, maxBins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform a grid search on a set of parameter values\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(rf.numTrees, [2, 5])\\\n",
    "                         .addGrid(rf.maxDepth, [2, 5])\\\n",
    "                         .build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=grid, evaluator=evaluator)\n",
    "cvModel = cv.fit(trainData)\n",
    "evaluator.evaluate(cvModel.transform(testData))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
